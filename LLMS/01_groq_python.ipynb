{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq #type:ignore\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"groqKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":\"explique a diferença entre llm e langchain.responda em portugues\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-5a9edb0a-ccc4-4755-9146-52e11bbe0a16', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Excelente pergunta!\\n\\nLLaMA (Large Language Model Application) e LangChain são dois modelos de linguagem grandes e avançados desenvolvidos pela Meta AI (antiga Facebook AI). Embora compartilhem muitas características, há algumas diferenças importantes entre eles. Aqui estão algumas diferenças principais:\\n\\n1. **Arquitetura**: LLaMA é um modelo de linguagem autônomo, projetado para realizar tarefas como geração de texto, classificação de texto e tradução. Já LangChain é um modelo mais flexível, que pode ser usado como uma linguagem de programação para criar aplicações de linguagem.\\n2. **Tamanho do modelo**: LLaMA é um modelo mais pequeno em tamanho, com cerca de 13 bilhões de parâmetros. LangChain, por outro lado, é um modelo mais grande, com cerca de 30 bilhões de parâmetros.\\n3. **Âmbito de aplicação**: LLaMA é projetado para aplicação em áreas como assistência virtual, respostas de chatbots e geração de conteúdo. LangChain, por sua vez, é projetado para ser mais genérico e pode ser usado em uma ampla variedade de áreas, incluindo machine learning, linguagem natural, robótica, etc.\\n4. **Comunicação entre modelos**: LLaMA é projetado para ser usado sozinho, enquanto LangChain é projetado para ser usado em conjunto com outros modelos e tecnologias, permitindo comunicação bidirecional entre eles.\\n5. **Personalização**: LLaMA é projetado para ser personalizado para diferentes tarefas e domínios, enquanto LangChain é projetado para ser mais flexível e pode ser usado em uma ampla variedade de aplicativos sem a necessidade de personalização adicional.\\n6. **Limitações**: LLaMA tem limitações em termos de sua capacidade de gerar textos longos e complexos, enquanto LangChain é projetado para gerar textos mais longos e complexos.\\n\\nEm resumo, LLaMA é um modelo de linguagem mais especializado e projetado para tarefas específicas, enquanto LangChain é um modelo mais geral e flexível que pode ser usado em uma ampla variedade de áreas.', role='assistant', function_call=None, reasoning=None, tool_calls=None))], created=1741370029, model='llama3-8b-8192', object='chat.completion', system_fingerprint='fp_6a6771ae9c', usage=CompletionUsage(completion_tokens=492, prompt_tokens=29, total_tokens=521, completion_time=0.41, prompt_time=0.01142822, queue_time=0.018277598, total_time=0.42142822), x_groq={'id': 'req_01jnrvvwzvfw38hsd0sy8rg0k8'})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    messages=mensagens,\n",
    "    model=\"llama3-8b-8192\"\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelente pergunta!\n",
      "\n",
      "LLaMA (Large Language Model Application) e LangChain são dois modelos de linguagem grandes e avançados desenvolvidos pela Meta AI (antiga Facebook AI). Embora compartilhem muitas características, há algumas diferenças importantes entre eles. Aqui estão algumas diferenças principais:\n",
      "\n",
      "1. **Arquitetura**: LLaMA é um modelo de linguagem autônomo, projetado para realizar tarefas como geração de texto, classificação de texto e tradução. Já LangChain é um modelo mais flexível, que pode ser usado como uma linguagem de programação para criar aplicações de linguagem.\n",
      "2. **Tamanho do modelo**: LLaMA é um modelo mais pequeno em tamanho, com cerca de 13 bilhões de parâmetros. LangChain, por outro lado, é um modelo mais grande, com cerca de 30 bilhões de parâmetros.\n",
      "3. **Âmbito de aplicação**: LLaMA é projetado para aplicação em áreas como assistência virtual, respostas de chatbots e geração de conteúdo. LangChain, por sua vez, é projetado para ser mais genérico e pode ser usado em uma ampla variedade de áreas, incluindo machine learning, linguagem natural, robótica, etc.\n",
      "4. **Comunicação entre modelos**: LLaMA é projetado para ser usado sozinho, enquanto LangChain é projetado para ser usado em conjunto com outros modelos e tecnologias, permitindo comunicação bidirecional entre eles.\n",
      "5. **Personalização**: LLaMA é projetado para ser personalizado para diferentes tarefas e domínios, enquanto LangChain é projetado para ser mais flexível e pode ser usado em uma ampla variedade de aplicativos sem a necessidade de personalização adicional.\n",
      "6. **Limitações**: LLaMA tem limitações em termos de sua capacidade de gerar textos longos e complexos, enquanto LangChain é projetado para gerar textos mais longos e complexos.\n",
      "\n",
      "Em resumo, LLaMA é um modelo de linguagem mais especializado e projetado para tarefas específicas, enquanto LangChain é um modelo mais geral e flexível que pode ser usado em uma ampla variedade de áreas.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excelente pergunta!\n",
      "\n",
      "LLaMA (Localized Large Memory Augmented) e LangChain são duas tecnologias diferentes desenvolvidas para imitar a linguagem humana, mas com abordagens e propósitos distintos.\n",
      "\n",
      "LLaMA é uma API (Application Programming Interface) que utiliza um modelo de linguagem treinado com dados de treinamento massivos e baseado em técnicas de processamento de linguagem neural. Ele é projetado para realizar tarefas de pré-processamento de linguagem, como tradução, geração de texto, resumo de texto e mais.\n",
      "\n",
      "LLaMA é conhecido por sua capacidade de entender e gerar texto de alta qualidade, porém é limitado por suas habilidades específicas e não é projetado para realizar tarefas mais complexas, como resolver problemas ou tomar decisões.\n",
      "\n",
      "Já LangChain é uma plataforma de inteligência artificial que se concentra em linguagem natural e processamento de linguagem. Ela é projetada para ser um assistente de linguagem que pode realizar uma ampla variedade de tarefas, desde lidar com dados, manipular texto, processar linguagem natural até realizar tarefas de linguagem mais avançadas, como geração de resposta, resumo de texto e mais.\n",
      "\n",
      "O principal ponto de destaque da LangChain é sua capacidade de aprender e melhorar com o tempo, através da interação com usuários e feedback. Isso permite que ela se adapte às necessidades específicas de cada usuário e desenvolva habilidades mais especializadas.\n",
      "\n",
      "Em resumo, LLaMA é uma ferramenta específica para tarefas de linguagem, enquanto LangChain é uma plataforma mais amplos que se concentra em linguagem natural e processamento de linguagem, com habilidades mais avançadas e capaz de aprender com o tempo.\n",
      "\n",
      "Espero que isso tenha ajudado a esclarecer a diferença entre essas tecnologias!None"
     ]
    }
   ],
   "source": [
    "mensagens = [\n",
    "    {\"role\":\"user\",\n",
    "     \"content\":\"explique a diferença entre llm e langchain.responda em portugues\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=mensagens,\n",
    "    model=\"llama3-8b-8192\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk.choices[0].delta.content,end=\"\",flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transcrição de audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def format_text(response):\n",
    "    text = response.text\n",
    "    text_formated = textwrap.fill(text,width=100)\n",
    "    print(text_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Seja muito bem vindo e bem vinda ao curso desbravando IA com Python explorando modelos de\n",
      "huggingface Neste curso eu quero te mostrar uma das maiores plataformas de inteligência artificial\n",
      "que possui diversos modelos prontos que é a plataforma do huggingface E o meu objetivo nesse curso é\n",
      "explorar dois tipos de modelos modelos relacionados a processamento de linguagem natural onde\n",
      "estaremos trabalhando com análise de sentimentos, vamos trabalhar também com informações de\n",
      "perguntas e respostas, vamos trabalhar também com modelos que nos ajudem a resumir textos e assim\n",
      "por diante. Por outro lado, nós teremos também modelos relacionados à visão computacional. Estaremos\n",
      "trabalhando com aplicações para segmentar imagens, classificar imagens, detectar objetos e muito\n",
      "mais. space além disso em algumas sessões você vai ter a oportunidade de construir o teu modelo é\n",
      "uma interface web para o teu modelo utilizando a biblioteca grade e também vamos aprender a colocar\n",
      "a aplicação que construirmos em produção utilizando o hugin faces no space espero que você possa\n",
      "estar empolgado para esse curso pois estou muito empolgado para disseminar esse conhecimento\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq #type:ignore\n",
    "\n",
    "\n",
    "client = Groq(api_key=os.getenv(\"groqKey\"))\n",
    "\n",
    "arquivo = \"curso.mp3\"\n",
    "\n",
    "with open(arquivo,\"rb\") as audio:\n",
    "    transcrição = client.audio.transcriptions.create(\n",
    "        file=(arquivo,audio.read()),\n",
    "        model=\"whisper-large-v3\",\n",
    "        response_format=\"json\",\n",
    "        language=\"pt\",\n",
    "        prompt=\"este e um curso de huggingface que usa aplicação com gradio\"\n",
    "    )\n",
    "\n",
    "format_text(transcrição)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "def format_text(response):\n",
    "    text = response.content\n",
    "    text_formated = textwrap.fill(text,width=100)\n",
    "    print(text_formated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-11b-vision-preview\",\n",
    "    messages=[{\"role\":\"user\",\n",
    "               \"content\":[\n",
    "                   {\"type\":\"text\",\"text\":\"o que há nessa imagem?\"},\n",
    "                   {\"type\":\"image_url\",\"image_url\":{\n",
    "                       \"url\":\"https://www.civitatis.com/blog/wp-content/uploads/2023/12/shutterstock_318248558-scaled.jpg\"\n",
    "                   }}\n",
    "               ]}],\n",
    "               temperature=1,\n",
    "               max_completion_tokens=1024,\n",
    "               top_p=1,\n",
    "               stream=False,\n",
    "               stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A imagem revela a beleza de uma praia urbana, com uma infraestrutura muito bem desenvolvida, uma\n",
      "estrada de laje, sombreada com palmeiras, iluminada por faixas de iluminação. Centenas de pessoas se\n",
      "encontram em solo arejado, desde que crianças brincando, até também homens e mulheres tomando sol.\n",
      "Seus corpos de banho coloridos contrastam e contrastam com uma água marinha azul-claro, enquanto,\n",
      "longe de todos os demais presentes na imagem, há uma escorregadia e dura rocha recortada, uma\n",
      "montanha que, mal se vê, fica no horizonte, subindo do mar, com muito menos árvores que os galhos da\n",
      "montanha falecem. Porém, um pouco, o contraste de azul, trazendo o céu igual ao mar, deixando-a\n",
      "amarelada, como creme já na medida, passando de cor aos primeiros sol setençãoais. Dentro de nuvens\n",
      "como as brancas, outras cinza já saindo na porta. Trata-se de um dia bem nublado, mas bem rufão e\n",
      "não chuvoso. Por causa da montanha, percebe-se que os presentes tem muitos horizontes, visto que a\n",
      "montanha esbarra em sua frente, segurando os horizontes bem como segura os olhos de todos, ouvindo o\n",
      "tamanho e a importância do presente esteticamente, através da praia, além do mar, atrás da montanha\n",
      "e ao centro da imagem, sendo um belíssimo sol.\n"
     ]
    }
   ],
   "source": [
    "format_text(completion.choices[0].message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
