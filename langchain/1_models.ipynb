{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI #type:ignore\n",
    "import os \n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\",api_key=os.getenv(\"openaiKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"conte uma historia sobre o aprendizado de maquina\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nEra uma vez um jovem cientista chamado Lucas que estava sempre em busca de novos desafios e descobertas. Um dia, ele se deparou com um campo de estudo fascinante e inovador: o aprendizado de m√°quina.\\n\\nLucas ficou impressionado com as possibilidades dessa √°rea, que consiste em ensinar uma m√°quina a aprender e realizar tarefas sem a necessidade de programa√ß√£o espec√≠fica. Ele decidiu se dedicar a esse campo de estudo e mergulhou de cabe√ßa no aprendizado de m√°quina.\\n\\nNo in√≠cio, Lucas encontrou muitas dificuldades e obst√°culos, afinal, era um campo muito novo e complexo. Mas ele n√£o se deixou abater e continuou a estudar e a se aprofundar no assunto.\\n\\nCom o tempo, Lucas foi entendendo melhor os conceitos e as t√©cnicas do aprendizado de m√°quina e come√ßou a aplic√°-los em suas pesquisas. Ele ficou maravilhado com os resultados que conseguia obter e como a m√°quina era capaz de aprender com base nos dados fornecidos.\\n\\nLucas tamb√©m se deparou'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Era uma vez, em uma cidade chamada Tecn√≥polis, um jovem chamado Lucas que sempre foi fascinado por tecnologia e inova√ß√£o. Desde pequeno, ele sonhava em criar m√°quinas inteligentes que pudessem ajudar a humanidade de alguma forma. Por isso, quando cresceu, decidiu estudar ci√™ncia da computa√ß√£o na melhor faculdade da cidade.\n",
      "\n",
      "Durante seus estudos, Lucas se deparou com uma disciplina que despertou ainda mais sua curiosidade: Aprendizado de M√°quina. Ele rapidamente se apaixonou pelo assunto e decidiu se aprofundar nessa √°rea.\n",
      "\n",
      "O Aprendizado de M√°quina, tamb√©m conhecido como Machine Learning, √© uma t√©cnica da intelig√™ncia artificial que permite que as m√°quinas aprendam a partir de dados e experi√™ncias, sem serem explicitamente programadas para isso. Ou seja, √© como se a m√°quina fosse capaz de aprender e tomar decis√µes por si s√≥.\n",
      "\n",
      "Lucas ficou encantado com essa ideia e decidiu fazer sua pesquisa de conclus√£o de curso sobre o tema. Ele passava horas e horas estudando"
     ]
    }
   ],
   "source": [
    "for trecho in llm.stream(prompt):\n",
    "    print(trecho,end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "perguntas = [\"o que e memoria ram?\",\"o que e o disco rigido?\",\"o que e o processador?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\nMem√≥ria RAM √© um tipo de mem√≥ria vol√°til (perde os dados quando o computador √© desligado) utilizada em computadores e dispositivos eletr√¥nicos para armazenar temporariamente dados e programas em execu√ß√£o. Ela √© respons√°vel por armazenar as informa√ß√µes que est√£o sendo utilizadas no momento, permitindo que o processador tenha acesso mais r√°pido a elas. Quanto maior a quantidade de mem√≥ria RAM, maior a capacidade de processamento do computador.',\n",
       " '\\n\\nO disco r√≠gido, tamb√©m conhecido como HD (Hard Disk), √© um dispositivo de armazenamento de dados utilizado em computadores e outros dispositivos eletr√¥nicos. Ele √© respons√°vel por armazenar permanentemente todos os arquivos, programas e informa√ß√µes do sistema operacional do computador. √â composto por discos magn√©ticos que giram a uma alta velocidade e uma cabe√ßa de leitura e grava√ß√£o que l√™ e escreve os dados no disco. ',\n",
       " '\\n\\nO processador √© um componente de hardware respons√°vel por executar as instru√ß√µes e opera√ß√µes de um computador. Ele √© considerado o \"c√©rebro\" da m√°quina, pois √© respons√°vel por processar os dados e comandos, controlar os dispositivos de entrada e sa√≠da e gerenciar o desempenho do sistema como um todo. Sem o processador, o computador n√£o seria capaz de funcionar. ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",api_key=os.getenv(\"openaiKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "\n",
    "mensagens = [SystemMessage(content=\"voce e um assistente que responde com ironia.\"),\n",
    "             HumanMessage(content=\"qual o papel da memoria cache?\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resposta = chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ah, a mem√≥ria cache, aquela que ajuda a deixar tudo mais r√°pido, como se fosse o caf√© expresso da computa√ß√£o. Ela armazena temporariamente informa√ß√µes frequentemente acessadas para que o processador n√£o precise ficar buscando no disco o tempo todo. √â como ter um assistente pessoal que te traz as coisas na hora que voc√™ pede, s√≥ que no mundo dos bits e bytes.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_usage': {'completion_tokens': 93,\n",
       "  'prompt_tokens': 31,\n",
       "  'total_tokens': 124,\n",
       "  'completion_tokens_details': {'accepted_prediction_tokens': 0,\n",
       "   'audio_tokens': 0,\n",
       "   'reasoning_tokens': 0,\n",
       "   'rejected_prediction_tokens': 0},\n",
       "  'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}},\n",
       " 'model_name': 'gpt-3.5-turbo-0125',\n",
       " 'system_fingerprint': None,\n",
       " 'finish_reason': 'stop',\n",
       " 'logprobs': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resposta.response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Few Shot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(api_key=os.getenv(\"openaiKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "mensagens = [HumanMessage(content=\"qual e o primeiro dia da semana?\"),\n",
    "             AIMessage(content=\"domingo\"),\n",
    "             HumanMessage(content=\"qual e o terceiro dia da semana?\"),\n",
    "             AIMessage(content=\"ter√ßa-feira\"),\n",
    "             HumanMessage(content=\"qual o ultimo dia da semana?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='s√°bado', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 53, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f2fcee6b-88fb-4d78-bbda-985fdfdc6d8c-0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: qual e o primeiro dia da semana?\\nAI: domingo\\nHuman: qual e o terceiro dia da semana?\\nAI: ter√ßa-feira\\nHuman: qual o ultimo dia da semana?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [1.08s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"s√°bado\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"s√°bado\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 3,\n",
      "                \"prompt_tokens\": 53,\n",
      "                \"total_tokens\": 56,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b5df65ce-982f-44fa-b012-69129e8507fc-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 3,\n",
      "      \"prompt_tokens\": 53,\n",
      "      \"total_tokens\": 56,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='s√°bado', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 53, 'total_tokens': 56, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-b5df65ce-982f-44fa-b012-69129e8507fc-0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cacheamento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\",api_key=os.getenv(\"openaiKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage\n",
    "\n",
    "mensagens = [SystemMessage(content=\"voce e um assistente ironico\"),\n",
    "             HumanMessage(content=\"qual o quinto dia da semana?\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 ms, sys: 1.85 ms, total: 15.3 ms\n",
      "Wall time: 3.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Segundo a maioria dos calend√°rios, o quinto dia da semana √© a sexta-feira. Mas se voc√™ estiver se referindo a algum calend√°rio alternativo ou se estiver tentando me pegar, parab√©ns pela tentativa! üòâ', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 27, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4253702f-3b5a-44f2-b4b0-e966327ff75d-0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 604 Œºs, sys: 0 ns, total: 604 Œºs\n",
      "Wall time: 592 Œºs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Segundo a maioria dos calend√°rios, o quinto dia da semana √© a sexta-feira. Mas se voc√™ estiver se referindo a algum calend√°rio alternativo ou se estiver tentando me pegar, parab√©ns pela tentativa! üòâ', response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 27, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4253702f-3b5a-44f2-b4b0-e966327ff75d-0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path=\"langchain_cache.sqlite\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.9 ms, sys: 1.97 ms, total: 24.9 ms\n",
      "Wall time: 1.07 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o \"quintou\", u√©! Brincadeiras √† parte, o quinto dia da semana √© a quinta-feira.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 27, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d9e2f356-b1c9-40b1-b70d-bf37eeb65f86-0')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.3 ms, sys: 6.82 ms, total: 21.2 ms\n",
      "Wall time: 20.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='O quinto dia da semana √© o \"quintou\", u√©! Brincadeiras √† parte, o quinto dia da semana √© a quinta-feira.', response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 27, 'total_tokens': 63, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d9e2f356-b1c9-40b1-b70d-bf37eeb65f86-0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
