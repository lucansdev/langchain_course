{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.Client(api_key=os.getenv(\"openaiKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_stores = client.beta.vector_stores.create(\n",
    "    name=\"tutor de apostilas\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = [\"LLM.pdf\"]\n",
    "file_stream = [open(f,\"rb\") for f in file]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_stores.id,files=file_stream\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_batch.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_batch.file_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"tutor apostila\",\n",
    "    instructions=\"você é um tutor especializados em tecnologias emergentes. você sabe responder perguntas sobre LLMs com OpenAI,huggingface,etc. \\\n",
    "        caso você  nao encontre as respostas, seja sincero e fale que não sabe responder.\",\n",
    "\n",
    "    tools=[{\"type\":\"file_search\"}],\n",
    "    tool_resources={\"file_search\":{\"vector_store_ids\":[vector_stores.id]}},\n",
    "    model=\"gpt-4-turbo-preview\"\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pergunta = \"conforme o documento, o que e o huggingface ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()\n",
    "mensagens = client.beta.threads.messages.create(thread_id=thread.id,role=\"user\",content=pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(thread_id=thread.id,assistant_id=assistant.id,instructions=\"nome de usuario premium\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "while run.status in [\"queued\",\"in_progress\",\"cancelling\"]:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id,run_id=run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_Y8cKwdAg20jVUbW5LHYxl31h', assistant_id='asst_MjvQmAJZxWsmVAyFboRITXoG', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=510, file_citation=FileCitation(file_id='file-9FkF6uoC6VjRXtktU198M8'), start_index=497, text='【4:0†LLM.pdf】', type='file_citation')], value='Hugging Face é descrita no documento como uma comunidade de código aberto que reúne centenas de milhares de modelos contribuídos que podem ajudar a resolver muitos casos de uso específicos, como geração de texto, resumo e classificação. Ela é destacada por seu crescimento explosivo nos últimos anos dentro do campo aberto de modelos de linguagem, mostrando uma rápida aproximação do desempenho dos modelos proprietários, apesar de ainda não alcançar o desempenho de modelos avançados como o GPT-4【4:0†LLM.pdf】.'), type='text')], created_at=1740592417, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_335Eb2Zn7Lr0xOkKcZMuMw58', status=None, thread_id='thread_AVeZJwfkxdLklgD4xmLK8XHN'), Message(id='msg_YOQk5ZmIWLtTqWd8FJfgLeGu', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='conforme o documento, o que e o huggingface ?'), type='text')], created_at=1740592409, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_AVeZJwfkxdLklgD4xmLK8XHN')], has_more=False, object='list', first_id='msg_Y8cKwdAg20jVUbW5LHYxl31h', last_id='msg_YOQk5ZmIWLtTqWd8FJfgLeGu')\n"
     ]
    }
   ],
   "source": [
    "if run.status == \"completed\":\n",
    "    mensagens = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "    print(mensagens)\n",
    "else:\n",
    "    print(f\"erro{run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hugging Face é descrita no documento como uma comunidade de código aberto que reúne centenas de milhares de modelos contribuídos que podem ajudar a resolver muitos casos de uso específicos, como geração de texto, resumo e classificação. Ela é destacada por seu crescimento explosivo nos últimos anos dentro do campo aberto de modelos de linguagem, mostrando uma rápida aproximação do desempenho dos modelos proprietários, apesar de ainda não alcançar o desempenho de modelos avançados como o GPT-4【4:0†LLM.pdf】.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mensagens.data[0].content[0].text.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
